---
output:
  html_document:
    toc: true
    toc_float: true
    theme: lumen
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(message = FALSE)
```

<br>

This section is part of a series that serves as a condensed summary of the [R for Data Science](http://r4ds.had.co.nz/index.html) book as I work through it. The purpose is to use this series as a quick reference in future.

First, we install/load the relevant packages by installing the [tidyverse](https://www.tidyverse.org/) library. This "package" effectively contains all packages developed by *the* [Hadley Wickham](http://hadley.nz/) that relate to the [tidy data](https://www.jstatsoft.org/article/view/v059i10) way of thinking. This chapter focuses on specific libraries, but we install and load the whole `tidyverse` anyway:

```{r load}
if (!require("tidyverse")) install.packages("tidyverse")
```

# Data Import

## Getting Started

### Loading with `readr`

Most of readr’s functions are concerned with turning flat files into data frames:

+ `read_csv()` - comma delimited files

+ `read_csv2()` - semicolon separated files

+ `read_tsv()` - tab delimited files

+ `read_delim()` - any delimiter

+ `read_fwf()` - fixed width files. You can specify fields either by their widths with `fwf_widths()` or their position with `fwf_positions()`.

+ `read_table()` reads a common variation of fixed width files where columns are separated by white space.

+ `read_log()` reads Apache style log files

When using these functions the nice feature about them is that they print out a column specification that gives the name and type of each column.


### Use Case for `read_csv`

`read_csv()` uses the first line of the data for the column names, which is a very common convention. There are two cases where you might want to tweak this behaviour:

1. Sometimes there are a few lines of metadata at the top of the file. You can use `skip = n` to skip the first `n` lines; or use `comment = "#"` to drop all lines that start with (e.g.) `#`.

```{r}
read_csv("The first line of metadata
  The second line of metadata
  x,y,z
  1,2,3", skip = 2)
```


```{r}
read_csv("# A comment I want to skip
  x,y,z
  1,2,3", comment = "#")
```


2. The data might not have column names. You can use `col_names = FALSE` to tell `read_csv()` not to treat the first row as headings.

```{r}
read_csv("1,2,3\n4,5,6", col_names = FALSE)
```


### Compared to base R

If you’ve used R before, you might wonder why we’re not using `read.csv()`. 

* Readr functions are typically much faster (~10x) than their base equivalents. Long running jobs have a progress bar, so you can see what’s happening. If you’re looking for raw speed, try `data.table::fread()`.

* They produce tibbles, they don’t convert character vectors to factors, use row names, or munge the column names. These are common sources of frustration with the base R functions.

* They are more reproducible. Base R functions inherit some behaviour from your operating system and environment variables, so import code that works on your computer might not work on someone else’s.


## Parsing a Vector

To understand how to read a file from disk, we need to take a little detour to talk about the `parse_*()~ functions`. These functions take a character vector and return a more specialised vector like a logical, integer, or date. Thy form the bulding blocks for readr. 

Using parsers is mostly a matter of understanding what’s available and how they deal with different types of input. There are eight particularly important parsers:


1. `parse_logical()` and `parse_integer()` parse logicals and integers respectively. 

2. `parse_double()` is a strict numeric parser, and `parse_number()` is a flexible numeric parser.

3. `parse_character()`

4. `parse_factor()` create factors, the data structure that R uses to represent categorical variables with fixed and known values.

5. `parse_datetime()`, `parse_date()`, and `parse_time()` allow you to parse various date & time specifications.


### Numbers

Complications with numbers:

1. Number separators are typically `.` or `,` for fractions. This typically solved with the notion of a locale:
```{r}
parse_double("1.23")
parse_double("1,23", locale = locale(decimal_mark = ","))
```

2. Numbers can be surrounded by other characters such as `%` or `$`. This typically solved with `parse_number()`, which ignores non-numeric characters before and after the number:
```{r}
parse_number("$100")
parse_number("20%")
parse_number("It cost $123.45")
```

3. "Grouping" characters, such as the `,` in 1,000,000. This is typically soved with the combination of `parse_number()` and the locale as `parse_number()` will ignore the “grouping mark”:
```{r}
parse_number("$123,456,789")
parse_number("123.456.789", locale = locale(grouping_mark = "."))
parse_number("123'456'789", locale = locale(grouping_mark = "'"))
```


### Strings

Readr uses UTF-8 for character encodings everywhere.This is a good default, but will fail for data produced by older systems that don’t understand UTF-8. If this happens to you, your strings will look weird when you print them. Sometimes just one or two characters might be messed up; other times you’ll get complete gibberish: 

```{r}
x1 <- "El Ni\xf1o was particularly bad this year"
x2 <- "\x82\xb1\x82\xf1\x82\xc9\x82\xbf\x82\xcd"
```

To fix the problem you need to specify the encoding in `parse_character()`:

```{r}
parse_character(x1, locale = locale(encoding = "Latin1"))
parse_character(x2, locale = locale(encoding = "Shift-JIS"))
```

To find the correct encoding is tricky. `guess_encoding()` can help figure it out. 
```{r}
guess_encoding(charToRaw(x1))
guess_encoding(charToRaw(x2))
```

Find a more detailed explanation at http://kunststube.net/encoding/.


### Factors

R uses factors to represent categorical variables that have a known set of possible values.

```{r}
fruit <- c("apple", "banana")
parse_factor(c("apple", "banana", "bananana"), levels = fruit)
```

If you have many problematic entries, it’s often easier to leave as character vectors and then use the tools you’ll learn about in strings and factors to clean them up.


### Dates, date-times, and times

You pick between three parsers depending on whether you want a date (the number of days since 1970-01-01), a date-time (the number of seconds since midnight 1970-01-01), or a time (the number of seconds since midnight). When called without any additional arguments:\

+ `parse_datetime()` expects an ISO8601 date-time.

```{r}
parse_datetime("2010-10-01T2010")

parse_datetime("20101010")
```

For more info on the ISO standard, checkout https://en.wikipedia.org/wiki/ISO_8601.

+ `parse_date()` expects a four digit year, a `-` or `/`, the month, a `-` or `/`, then the day

```{r}
parse_date("2010-10-01")
```


+ `parse_time()` expects the hour, `:`, minutes, optionally `:` and seconds, and an optional am/pm specifier:

```{r}
library(hms)
parse_time("01:10 am")
parse_time("20:10:01")
```

For date and time formatting, check out [this page](https://www.stat.berkeley.edu/~s133/dates.html). If these default formats don't work for you, you can read more about customising your format [here](https://r4ds.had.co.nz/data-import.html#readr-datetimes).


## Parsing a File

readr uses a heuristic to figure out the type of each column: it reads the first 1000 rows and uses some (moderately conservative) heuristics to figure out the type of each column. It uses `parse_guess()`

```{r}
guess_parser("2010-10-01")
guess_parser("15:01")
guess_parser(c("TRUE", "FALSE"))
guess_parser(c("1", "5", "9"))
guess_parser(c("12,352,561"))

str(parse_guess("2010-10-10"))
```


The heuristic tries each of the following types, stopping when it finds a match:

+ logical: contains only “F”, “T”, “FALSE”, or “TRUE”.
+ integer: contains only numeric characters (and -).
+ double: contains only valid doubles (including numbers like 4.5e-5).
+ number: contains valid doubles with the grouping mark inside.
+ time: matches the default time_format.
+ date: matches the default date_format.
+ date-time: any ISO8601 date.

If none of these rules apply, then the column will stay as a vector of strings.


These defaults don’t always work for larger files. There are two basic problems:

1. The first thousand rows might be a special case, and readr guesses a type that is not sufficiently general. For example, you might have a column of doubles that only contains integers in the first 1000 rows.

2. The column might contain a lot of missing values. If the first 1000 rows contain only NAs, readr will guess that it’s a character vector, whereas you probably want to parse it as something more specific.

There are a few options for overcoming these strategies. Read about them [here](https://r4ds.had.co.nz/data-import.html#parsing-a-file)


## Writing to a File

Use `write_csv()` and `write_tsv()` to write data back to disc. Both functions always encoding strings in UTF-8 and save dates and date-times in ISO8601 format so they are easily parsed elsewhere. For Excel csv use `write_excel_csv()`. Using csv, though, loses columns types. There are two alternatives:

1. `write_rds()` and `read_rds()` which store data in R’s custom binary format called RDS.

2. The feather package implements a fast binary file format that can be shared across programming languages. Feather tends to be faster than RDS and is usable outside of R. RDS supports list-columns whereas feather currently does not.

## Other Types of Data

To get other types of data into R start with the tidyverse packages listed below:

+ *haven* reads SPSS, Stata, and SAS files.

+ *readxl* reads excel files (both `.xls` and `.xlsx`).

+ *DBI*, along with a database specific backend (e.g. RMySQL, RSQLite, RPostgreSQL etc) allows you to run SQL queries against a database and return a data frame.


For hierarchical data: use jsonlite (by Jeroen Ooms) for json, and xml2 for XML. Jenny Bryan has some excellent worked examples at https://jennybc.github.io/purrr-tutorial/.

For other file types, try the R data import/export manual and the `rio` package.