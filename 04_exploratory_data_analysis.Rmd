---
output:
  html_document:
    toc: true
    toc_float: true
    theme: lumen
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(message = FALSE)
```

<br>

This section is part of a series that serves as a condensed summary of the [R for Data Science](http://r4ds.had.co.nz/index.html) book as I work through it. The purpose is to use this series as a quick reference in future.

First, we install/load the relevant packages by installing the [tidyverse](https://www.tidyverse.org/) library. This "package" effectively contains all packages developed by *the* [Hadley Wickham](http://hadley.nz/) that relate to the [tidy data](https://www.jstatsoft.org/article/view/v059i10) way of thinking. This chapter focuses on specific libraries, but we install and load the whole `tidyverse` anyway:

```{r load}
if (!require("tidyverse")) install.packages("tidyverse")
library(tidyverse)
library(nycflights13)
```


# Exploratory Data Analysis

## The Theoretic Underpinning

Exploratory data analysis (EDA) is an iterative cycle:

1) Generate questions about your data.

2) Search for answers by visualising, transforming, and modelling your data.

3) Use what you learn to refine your questions and/or generate new questions.

> "Your goal during EDA is to develop an understanding of your data." - R For Data Science

Two useful questions to ask about your data:

1) What type of variation occurs within my variables?

2) What type of covariation occurs between my variables?

To facilitate these questions, let's define some terms:

* **Variable** - a quantity, quality, or property that you can measure.

* **Value** - the state of a variable when you measure it.

* **Observation** - a set of measurements made under similar conditions.

* **Tabular data** -a set of values, each associated with a variable and an observation.


## Variation

**Variation** is the tendency of the values of a variable to change from measurement to measurement.  Every variable has its own pattern of variation, which can reveal interesting information. The best way to understand that pattern is to visualise the distribution of the variable’s values.


### Visualising Distribution

How you visualise the distribution of a variable will depend on whether the variable is categorical or continuous. A variable is **categorical** if it can only take one of a small set of values. In R, categorical variables are usually saved as factors or character vectors. To examine the distribution of a categorical variable, use a bar chart:

```{r}
ggplot(data = diamonds) +
  
  geom_bar(mapping = aes(x = cut))
```


The height of the bars displays how many observations occurred with each x value. You can compute these values manually with `dplyr::count()`:

```{r}
diamonds %>% 
  
  count(cut)
```

A variable is **continuous** if it can take any of an infinite set of ordered values. To examine the distribution of a continuous variable, use a histogram:

```{r}
ggplot(data = diamonds) +
  
  geom_histogram(mapping = aes(x = carat), binwidth = 0.5)
```

You can compute this by hand by combining `dplyr::count()` and `ggplot2::cut_width()`:

```{r}
diamonds %>% 
  
  count(cut_width(carat, 0.5)) #??
```

A **histogram** divides the x-axis into equally spaced bins and then uses the height of a bar to display the number of observations that fall in each bin. You should always explore a variety of binwidths when working with histograms, as different binwidths can reveal different patterns. 

```{r}
smaller <- diamonds %>% 
  
  filter(carat < 3)
  
ggplot(data = smaller, mapping = aes(x = carat)) +
  
  geom_histogram(binwidth = 0.1)
```

If you wish to overlay multiple histograms in the same plot, use `geom_freqpoly()`instead of `geom_histogram()`. 

```{r}
ggplot(data = smaller, mapping = aes(x = carat, colour = cut)) +
  
  geom_freqpoly(binwidth = 0.1)
```

Having visualised variation, we need to interrogate the data. Here follow some questions we could ask. 

### Typical Values

Data visulisation helps us to turn descriptive information and typical values into useful questions. Consider the following for the `diamonds` data set:

```{r}
ggplot(data = smaller, mapping = aes(x = carat)) +
  
  geom_histogram(binwidth = 0.01)
```

- Which values are the most common? Why?

- Which values are rare? Why? Does that match your expectations?

- Can you see any unusual patterns? What might explain them?

- Why are there more diamonds at whole carats and common fractions of carats?

- Why are there more diamonds slightly to the right of each peak than there are slightly to the left of each peak?

- Why are there no diamonds bigger than 3 carats?

Clusters of similar values suggest that subgroups exist in your data. To understand the subgroups, ask:

- How are the observations within each cluster similar to each other?

- How are the observations in separate clusters different from each other?

- How can you explain or describe the clusters?

- Why might the appearance of clusters be misleading?

Clusters would look something like the Old Faithful data dataset:

```{r}
ggplot(data = faithful, mapping = aes(x = eruptions)) + 
  
  geom_histogram(binwidth = 0.25)
```


### Unusual Values

Outliers are observations that are unusual; data points that don’t seem to fit the pattern. Outliers are sometimes hard to spot:

```{r}
ggplot(diamonds) + 
  
  geom_histogram(mapping = aes(x = y), binwidth = 0.5)
```

To make it easy to see the unusual values, we need to zoom to small values of the y-axis with `coord_cartesian()`.

```{r}
ggplot(diamonds) + 
  
  geom_histogram(mapping = aes(x = y), binwidth = 0.5) +
  
  coord_cartesian(ylim = c(0, 50))
```

`xlim()` and `ylim()` zoom in on the data, or throw away the data outside the limits, depending on how it they are used.

We can see what's going on in the data with some `dplyr` magic:

```{r}
unusual <- 
  
  diamonds %>% 
  
  filter(y < 3 | y > 20) %>% 
  
  select(price, x, y, z) %>%
  
  arrange(y)

unusual
```


It’s good practice to repeat your analysis with and without the outliers. If they have minimal effect on the results, and you can’t figure out why they’re there, it’s reasonable to replace them with missing values, and move on. However, if they have a substantial effect on your results, you shouldn’t drop them without justification. You’ll need to figure out what caused them (e.g. a data entry error) and disclose that you removed them in your write-up.


## Missing Values

Unusual values can be removed from the data set, but this may adversely affect your dataset if you have a low quality data set. Instead, it might be useful to replace your unusual values with `NA`s:

```{r}
diamonds2 <- diamonds %>% 
  
  mutate(y = ifelse(y < 3 | y > 20, NA, y))
```


Use `?ifelse()` to find out more about that function. If you need to mutate based on more (or more complex) criteria, `dplyr::case_when()` comes in really useful. `case_when()` is particularly useful inside mutate when you want to create a new variable that relies on a complex combination of existing variables.

Package ggplot2 will tell you will tell you when it removes missing values:

```{r}
ggplot(data = diamonds2, mapping = aes(x = x, y = y)) + 
  
  geom_point()
```


Sometimes missing values themselves convey information, and should not just be disregarded as fillers. You might want to understand what makes observations with missing values different to observations with recorded values. For example, in `nycflights13::flights`, missing values in the `dep_time` variable indicate that the flight was cancelled. So you might want to compare the scheduled departure times for cancelled and non-cancelled times. You can do this by making a new variable with `is.na()`.

```{r}
nycflights13::flights %>% 
  
  mutate(
    
    cancelled = is.na(dep_time),
    
    sched_hour = sched_dep_time %/% 100,
    
    sched_min = sched_dep_time %% 100,
    
    sched_dep_time = sched_hour + sched_min / 60
    
  ) %>% 
  
  ggplot(mapping = aes(sched_dep_time)) + 
  
    geom_freqpoly(mapping = aes(colour = cancelled), binwidth = 1/4)
```

This comparison can still be improved, though.


## Covariation

If variation describes the behavior **within** a variable, covariation describes the behavior **between** variables. It is the tendency for the values of two or more variables to vary together in a related way.Determining the degree of covariation depends on the types of the variables involved.

If your dataset contained both categorical and continuous variables, for example, it might be desirable to breakdown the continuous variable according to the categorical variable, Here is an example with the `diamonds` data set: 

```{r}
ggplot(data = diamonds, mapping = aes(x = price)) + 
  
  geom_freqpoly(mapping = aes(colour = cut), binwidth = 500)
```

It is rather hard to see the difference in distribution because the overall counts differ so much:

```{r}
ggplot(diamonds) + 
  
  geom_bar(mapping = aes(x = cut))
```

We can fix this by having `geom_freqpoly()` plot according to density instead of the count. The *density* her eis the count standardised so that the area under each frequency polygon is one. 

```{r}
ggplot(data = diamonds, mapping = aes(x = price, y = ..density..)) + 
  
  geom_freqpoly(mapping = aes(colour = cut), binwidth = 500)
```


There’s something rather surprising about this plot - it appears that fair diamonds (the lowest quality) have the highest average price! But maybe that’s because frequency polygons are a little hard to interpret - there’s a lot going on in this plot.

Another alternative to display the distribution of a continuous variable broken down by a categorical variable is the boxplot:

```{r}
ggplot(data = diamonds, mapping = aes(x = cut, y = price)) +
  
  geom_boxplot()
```

Many categorical variables don’t an intrinsic order (good, fair, bad), so you might want to reorder them to make a more informative display. One way to do that is with the `reorder()` function. 

Take the `class` variable in the `mpg` dataset. You might be interested to know how highway mileage varies across classes:

```{r}
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) +
  
  geom_boxplot()
```

To make the trend easier to see, we can reorder `class` based on the median value of `hwy`:

```{r}
ggplot(data = mpg) +
  
  geom_boxplot(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy))
```

If you have long variable names, `geom_boxplot()` will work better if you flip it 90°. You can do that with `coord_flip()`.


```{r}
ggplot(data = mpg) +
  
  geom_boxplot(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy)) +
  
  coord_flip()
```


To visualise the covariation **between categorical variables**, you’ll need to count the number of observations for each combination. One way to do that is to rely on the `built-in geom_count()`:

```{r}
ggplot(data = diamonds) +
  
  geom_count(mapping = aes(x = cut, y = color))
```


Covariation will appear as a strong correlation between specific x values and specific y values.

Another approach is to compute the count with dplyr's `count()` and then visualise with `geom_tile()` and the fill aesthetic:

```{r}
diamonds %>% 
  
  count(color, cut) %>%  
  
  ggplot(mapping = aes(x = color, y = cut)) +
  
    geom_tile(mapping = aes(fill = n))
```

To visualise covaration **between continous variables**, simply construct a scatter plot using `geom_point()`.  You can see covariation as a pattern in the points. For example, you can see an exponential relationship between the carat size and price of a diamond.

```{r}
ggplot(data = diamonds) +
  
  geom_point(mapping = aes(x = carat, y = price))
```

Scatterplots become less useful as the size of your dataset grows, because points begin to overplot, and pile up into areas of uniform black. Use the `alpha` aesthetic to fix this. 

```{r}
ggplot(data = diamonds) + 
  
  geom_point(mapping = aes(x = carat, y = price), alpha = 1 / 100)
```

Even transparency, though, has its limits with very large datasets. Another useful approach is to bin the data. In addition to using `geom_histogram()` and `geom_freqpoly()` for binning one dimension, we can use `geom_bin2d()` and `geom_hex()` to bin two dimensions. The latter to functions divide the coordinate plane into two-dimensional bins and then fill with colour to indicate how many points fall in each bin.


```{r}
ggplot(data = smaller) +
  
  geom_bin2d(mapping = aes(x = carat, y = price))
```

In addition, there is a `geom_hex()` from the hexbin package that creates hexagons:

```{r}
# install.packages("hexbin")
ggplot(data = smaller) +
  
  geom_hex(mapping = aes(x = carat, y = price))
```

Another option is to bin one continuous variable so it acts like a categorical variable. Here is an example with `carat`, where `cut_width(x, width)` is used to divide `x` into bins of width `width`.

```{r}
ggplot(data = smaller, mapping = aes(x = carat, y = price)) + 
  
  geom_boxplot(mapping = aes(group = cut_width(carat, 0.1)))
```

We could also display approximately the same number of points in each bin using `cut_number()`

```{r}
ggplot(data = smaller, mapping = aes(x = carat, y = price)) + 
  
  geom_boxplot(mapping = aes(group = cut_number(carat, 20)))
```


## Patterns and Models

Patterns in your data provide clues about relationships. If you spot a pattern, ask yourself:

+ Could this pattern be due to coincidence (i.e. random chance)?

+ How can you describe the relationship implied by the pattern?

+ How strong is the relationship implied by the pattern?

+ What other variables might affect the relationship?

+ Does the relationship change if you look at individual subgroups of the data?


A scatterplot of Old Faithful eruption lengths versus the wait time between eruptions shows a pattern:

```{r}
ggplot(data = faithful) + 
  
  geom_point(mapping = aes(x = eruptions, y = waiting))
```

Patterns provide one of the most useful tools for data scientists because they reveal covariation. If you think of variation as a phenomenon that creates uncertainty, covariation is a phenomenon that reduces it. If the covariation is due to a causal relationship (a special case), then you can use the value of one variable to control the value of the second.

Models are a tool for extracting patterns out of data. For example, consider the diamonds data. It’s possible to use a model to remove the very strong relationship between two variables so we can explore the subtleties that remain.The following code fits a model that predicts `price` from `carat` and then computes the residuals (the difference between the predicted value and the actual value). The residuals give us a view of the price of the diamond, once the effect of carat has been removed.

```{r}
library(modelr)

mod <- lm(log(price) ~ log(carat), data = diamonds)


diamonds2 <- 
  
  diamonds %>% 
  
  add_residuals(mod) %>% 
  
  mutate(resid = exp(resid))


ggplot(data = diamonds2) + 
  
  geom_point(mapping = aes(x = carat, y = resid))
```

Once you’ve removed the strong relationship between carat and price, you can see what you expect in the relationship between cut and price: relative to their size, better quality diamonds are more expensive.

```{r}
ggplot(data = diamonds2) + 
  
  geom_boxplot(mapping = aes(x = cut, y = resid))
```

