---
output:
  html_document:
    toc: true
    toc_float: true
    theme: lumen
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(message = FALSE)
```

<br>

This section is part of a series that serves as a condensed summary of the [R for Data Science](http://r4ds.had.co.nz/index.html) book as I work through it. The purpose is to use this series as a quick reference in future.

First, we install/load the relevant packages by installing the [tidyverse](https://www.tidyverse.org/) library. This "package" effectively contains all packages developed by *the* [Hadley Wickham](http://hadley.nz/) that relate to the [tidy data](https://www.jstatsoft.org/article/view/v059i10) way of thinking. This chapter focuses on specific libraries, but we install and load the whole `tidyverse` anyway:

```{r load}
if (!require("tidyverse")) install.packages("tidyverse")
```

The focus of this chapter will be on regular expressions, or regexps for short. Regular expressions are useful because strings usually contain unstructured or semi-structured data, and regexps are a concise language for describing patterns in strings.This chapter will focus on the stringr package for string manipulation, which is part of the core tidyverse.

# String Basics

You can create strings with either single quotes or double quotes:

```{r}
string1 <- "This is a string"

string2 <- 'If I want to include a "quote" inside a string, I use single quotes'
```

To include a literal single or double quote in a string you can use \ to “escape” it:

```{r}
double_quote <- "\"" # or '"'

single_quote <- '\'' # or "'"
```

Beware that the printed representation of a string is not the same as string itself, because the printed representation shows the escapes. To see the raw contents of the string, use `writeLines()`:

```{r}
x <- c("\"", "\\")

writeLines(x)
```

The most common are "\n", newline, and "\t", tab. You can see the complete list by requesting help on ": ?'"', or ?"'". You’ll also sometimes see strings like "\u00b5", this is a way of writing non-English characters that works on all platforms:

```{r}
x <- "\u00b5"
x
```


Multiple strings are often stored in a character vector, which you can create with `c()`:

```{r}
c("one", "two", "three")
```


## String Length

We'll use some functions from the stringr package. These have more intuitive names, and all start with str_. For example, str_length() tells you the number of characters in a string:

```{r}
str_length(c("a", "R for data science", NA))
```


## Combining Strings

To combine two or more strings, `use str_c()`:

```{r}
str_c("x", "y")

str_c("x", "y", "z")

str_c("x", "y", sep = ", ")
```

If you want to print missing values as "NA", use `str_replace_na()`.

```{r}
x <- c("abc", NA)

str_c("|-", x, "-|")

str_c("|-", str_replace_na(x), "-|")
```

As shown above, `str_c()` is vectorised, and it automatically recycles shorter vectors to the same length as the longest:

```{r}
str_c("prefix-", c("a", "b", "c"), "-suffix")
```

Objects of length 0 are silently dropped. This is particularly useful in conjunction with `if`:

```{r}
name <- "Hadley"

time_of_day <- "morning"

birthday <- FALSE


str_c(
  
  "Good ", time_of_day, " ", name,
  
  if (birthday) " and HAPPY BIRTHDAY",
  
  "."
  
)
```

To collapse a vector of strings into a single string, use `collapse`:

```{r}
str_c(c("x", "y", "z"), collapse = ", ")
```

## Subsetting Strings

You can extract parts of a string using `str_sub()`:

```{r}
x <- c("Apple", "Banana", "Pear")

str_sub(string = x, start = 1, end = 3)
```

Note that `str_sub()` won’t fail if the string is too short; it will just return as much as possible:

```{r}
str_sub("a", 1, 5)
```

You can also use the assignment form of `str_sub()` to modify strings:

```{r}
str_sub(x, 1, 1) <- str_to_lower(str_sub(x, 1, 1))

x
```

## Locales

You can also use `str_to_upper()` or `str_to_title()`. However, changing case is more complicated than it might at first appear because different languages have different rules for changing case. You can pick which set of rules to use by specifying a locale:

```{r}
# Turkish has two i's: with and without a dot, and it
# has a different rule for capitalising them:
str_to_upper(c("i", "ı"))

str_to_upper(c("i", "ı"), locale = "tr")
```

The locale is specified as a ISO 639 language code, which is a two or three letter abbreviation. If you leave the locale blank, it will use the current locale, as provided by your operating system. Click [here](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) to see a list of ISO codes.

The base R `order()` and `sort()` functions sort strings using the current locale. If you want robust behaviour across different computers, you may want to use str_sort() and str_order() which take an additional locale argument:

```{r}
x <- c("apple", "eggplant", "banana")

str_sort(x, locale = "en")  # English

str_sort(x, locale = "haw") # Hawaiian
```


# Matching patterns with regular expressions

Regexps are a very terse language that allow you to describe patterns in strings.To learn regular expressions, we can use `str_view()` and `str_view_all()`.

## Basic matches

The simplest patterns match exact strings:

```{r}
x <- c("apple", "banana", "pear")

str_view(x, "an")
```

The next step up in complexity is `.`, which matches any character (except a newline):

```{r}
str_view(x, ".a.")
```


## Anchors

By default, regular expressions will match any part of a string. It’s often useful to _anchor_ the regular expression so that it matches from the start or end of the string.

+ `^` to match the start of the string.

+ `$` to match the end of the string.

```{r}
x <- c("apple", "banana", "pear")

str_view(x, "^a")
```


```{r}
str_view(x, "a$")
```


## Character Classes and Alternatives

 You’ve already seen what `.` can do. There are four other useful tools:
 
+ `\d`: matches any digit.

+ `\s`: matches any whitespace (e.g. space, tab, newline).

+ `[abc]`: matches a, b, or c.

+ `[^abc]`: matches anything except a, b, or c.

Remember, to create a regular expression containing `\d` or `\s`, you’ll need to escape the `\` for the string, so you’ll type "`\\d`" or "`\\s`".

A character class containing a single character is a nice alternative to backslash escapes when you want to include a single metacharacter in a regex. Many people find this more readable.

```{r}
# Look for a literal character that normally has special meaning in a regex

str_view(c("abc", "a.c", "a*c", "a c"), "a[.]c")
```

```{r}
str_view(c("abc", "a.c", "a*c", "a c"), ".[*]c")
```

```{r}
str_view(c("abc", "a.c", "a*c", "a c"), "a[ ]")
```

This works for most (but not all) regex metacharacters: `$` `.` `|` `?` `*` `+` `(` `)` `[` {. Unfortunately, a few characters have special meaning even inside a character class and must be handled with backslash escapes: `]` `\` `^` and `-`.


You can use _alternation_ to pick between one or more alternative patterns. For example, `abc|d..f` will match either ‘“abc”’, or "deaf". Note that the precedence for `|` is low, so that `abc|xyz` matches `abc` or `xyz` not `abcyz` or `abxyz.` Like with mathematical expressions, if precedence ever gets confusing, use parentheses to make it clear what you want:

```{r}
str_view(c("grey", "gray"), "gr(e|a)y")
```


## Repetition

The next step up in power involves controlling how many times a pattern matches:

+ `?`: 0 or 1

+ `+`: 1 or more

+ `*`: 0 or more


```{r}
x <- "1888 is the longest year in Roman numerals: MDCCCLXXXVIII"

str_view(x, "CC?")
```

```{r}
str_view(x, "CC+")
```

```{r}
str_view(x, 'C[LX]+')
```

Note that the precedence of these operators is high, so you can write: `colou?r` to match either American or British spellings. That means most uses will need parentheses, like `bana(na)+`.

You can also specify the number of matches precisely:

+ `{n}`: exactly n

+ `{n,}`: n or more

+ `{,m}`: at most m

+ `{n,m}`: between n and m

```{r}
str_view(x, "C{2}")
```

```{r}
str_view(x, "C{2,}")
```

```{r}
str_view(x, "C{2,3}")
```

By default these matches are “greedy”: they will match the longest string possible. You can make them “lazy”, matching the shortest string possible by putting a `?` after them. This is an advanced feature of regular expressions, but it’s useful to know that it exists:

```{r}
str_view(x, 'C{2,3}?')
```

```{r}
str_view(x, 'C[LX]+?')
```


## Grouping and backreferences

In addition to disambiguating complex expressions, parentheses also create a numbered capturing group (number 1, 2 etc.). A capturing group stores the part of the string matched by the part of the regular expression inside the parentheses. You can refer to the same text as previously matched by a capturing group with backreferences, like `\1`, `\2` etc. For example, the following regular expression finds all fruits that have a repeated pair of letters.

```{r}
str_view(fruit, "(..)\\1", match = TRUE)
```

# Tools

A word of caution before we continue: because regular expressions are so powerful, it’s easy to try and solve every problem with a single regular expression. In the words of Jamie Zawinski:

> Some people, when confronted with a problem, think “I know, I’ll use regular expressions.” Now they have two problems.


## Detect Matches

To determine if a character vector matches a pattern, `use str_detect()`.

```{r}
x <- c("apple", "banana", "pear")

str_detect(x, "e")
```

Remember that when you use a logical vector in a numeric context, `FALSE` becomes 0 and `TRUE` becomes 1. That makes `sum()` and `mean()` useful if you want to answer questions about matches across a larger vector:

```{r}
# How many common words start with t?
sum(str_detect(words, "^t"))

# What proportion of common words end with a vowel?
mean(str_detect(words, "[aeiou]$"))
```

When you have complex logical conditions (e.g. match a or b but not c unless d) it’s often easier to combine multiple `str_detect()` calls with logical operators, rather than trying to create a single regular expression. For example, here are two ways to find all words that don’t contain any vowels:

```{r}
# Find all words containing at least one vowel, and negate

no_vowels_1 <- !str_detect(words, "[aeiou]")

# Find all words consisting only of consonants (non-vowels)

no_vowels_2 <- str_detect(words, "^[^aeiou]+$")

identical(no_vowels_1, no_vowels_2)
```

A common use of `str_detect()` is to select the elements that match a pattern. You can do this with logical subsetting, or the convenient `str_subset()` wrapper:

```{r}
words[str_detect(words, "x$")]
```

```{r}
str_subset(words, "x$")
```

Typically, however, your strings will be one column of a data frame, and you’ll want to use `filter()` instead:

```{r}
df <- tibble(
  
  word = words, 
  
  i = seq_along(word)
  
)

df %>% 
  
  filter(str_detect(word, "x$"))
```


A variation on `str_detect()` is `str_count()`: rather than a simple yes or no, it tells you how many matches there are in a string:

```{r}
x <- c("apple", "banana", "pear")

str_count(x, "a")

# On average, how many vowels per word?

mean(str_count(words, "[aeiou]"))
```


It’s natural to use `str_count()` with `mutate()`:

```{r}
df %>% 
  
  mutate(
    
    vowels = str_count(word, "[aeiou]"),
    
    consonants = str_count(word, "[^aeiou]")
    
  )
```

Note that matches never overlap. For example, in `"abababa"`, how many times will the pattern `"aba"` match? Regular expressions say two, not three:


```{r}
str_count("abababa", "aba")

str_view_all("abababa", "aba")
```


## Extract Matches

To extract the actual text of a match, use `str_extract()`. Let's use [Harvard Sentences](https://en.wikipedia.org/wiki/Harvard_sentences), also found in `stringr::sentences` to practice on:

```{r}
length(sentences)

head(sentences)
```

Imagine we want to find all sentences that contain a colour. We first create a vector of colour names, and then turn it into a single regular expression:

```{r}
colours <- c("red", "orange", "yellow", "green", "blue", "purple")

colour_match <- str_c(colours, collapse = "|")

colour_match
```

Now we can select the sentences that contain a colour, and then extract the colour to figure out which one it is:

```{r}
has_colour <- str_subset(sentences, colour_match)

matches <- str_extract(has_colour, colour_match)

head(matches)
```

Note that `str_extract()` only extracts the first match. We can see that most easily by first selecting all the sentences that have more than 1 match:

```{r}
more <- sentences[str_count(sentences, colour_match) > 1]

str_view_all(more, colour_match)

str_extract(more, colour_match)
```

This is a common pattern for stringr functions, because working with a single match allows you to use much simpler data structures. To get all matches, use `str_extract_all()`. It returns a list:

```{r}
str_extract_all(more, colour_match)
```

If you use `simplify = TRUE`, `str_extract_all()` will return a matrix with short matches expanded to the same length as the longest:

```{r}
str_extract_all(more, colour_match, simplify = TRUE)


x <- c("a", "a b", "a b c")

str_extract_all(x, "[a-z]", simplify = TRUE)
```


## Grouped Matches

You can also use parentheses to extract parts of a complex match. For example, imagine we want to extract nouns from the sentences.

```{r}
noun <- "(a|the) ([^ ]+)"

has_noun <- sentences %>%
  
  str_subset(noun) %>%
  
  head(10)


has_noun %>% 
  
  str_extract(noun)
```

`str_extract()` gives us the complete match; `str_match()` gives each individual component. Instead of a character vector, it returns a matrix, with one column for the complete match followed by one column for each group:

```{r}
 has_noun %>% 
  
  str_match(noun)
```

If your data is in a tibble, it’s often easier to use `tidyr::extract()`. It works like str_match() but requires you to name the matches, which are then placed in new columns:

```{r}
tibble(sentence = sentences) %>% 
  
  tidyr::extract(
    
    sentence, c("article", "noun"), "(a|the) ([^ ]+)", 
    
    remove = FALSE
  )
```

Like `str_extract()`, if you want all matches for each string, you’ll need `str_match_all()`.


## Replacing Matches

`str_replace()` and `str_replace_all()` allow you to replace matches with new strings. The simplest use is to replace a pattern with a fixed string:

```{r}
x <- c("apple", "pear", "banana")

str_replace(x, "[aeiou]", "-")

str_replace_all(x, "[aeiou]", "-")
```


With `str_replace_all()` you can perform multiple replacements by supplying a named vector:

```{r}
x <- c("1 house", "2 cars", "3 people")

str_replace_all(x, c("1" = "one", "2" = "two", "3" = "three"))
```

Instead of replacing with a fixed string you can use backreferences to insert components of the match. In the following code, I flip the order of the second and third words.

```{r}
sentences %>%
  
  str_replace("([^ ]+) ([^ ]+) ([^ ]+)", "\\1 \\3 \\2") %>% 
  
  head(5)
```


## Splitting

Use `str_split()` to split a string up into pieces. For example, we could split sentences into words:

```{r}
sentences %>%
  
  head(5) %>% 
  
  str_split(" ")
```

Because each component might contain a different number of pieces, this returns a list. If you’re working with a length-1 vector, the easiest thing is to just extract the first element of the list:

```{r}
"a|b|c|d" %>% 
  
  str_split("\\|") %>% 
  
  .[[1]]
```

Otherwise, like the other stringr functions that return a list, you can use `simplify = TRUE` to return a matrix:

```{r}
sentences %>%
  
  head(5) %>% 
  
  str_split(" ", simplify = TRUE)
```

You can also request a maximum number of pieces:

```{r}
fields <- c("Name: Hadley", "Country: NZ", "Age: 35")

fields %>% str_split(": ", n = 2, simplify = TRUE)
```

Instead of splitting up strings by patterns, you can also split up by character, line, sentence and word `boundary()`s:

```{r}
x <- "This is a sentence.  This is another sentence."

str_view_all(x, boundary("word"))
```


## Other Types of Pattern

When you use a pattern that’s a string, it’s automatically wrapped into a call to `regex()`:

```{r}
# The regular call:
str_view(fruit, "nana")

# Is shorthand for
str_view(fruit, regex("nana"))
```


You can use the other arguments of `regex()` to control details of the match:

+ `ignore_case = TRUE` allows characters to match either their uppercase or lowercase forms. This always uses the current locale.

```{r}
bananas <- c("banana", "Banana", "BANANA")

str_view(bananas, "banana")

str_view(bananas, regex("banana", ignore_case = TRUE))
```

+ `multiline = TRUE` allows ^ and $ to match the start and end of each line rather than the start and end of the complete string.

```{r}
x <- "Line 1\nLine 2\nLine 3"

str_extract_all(x, "^Line")[[1]]

str_extract_all(x, regex("^Line", multiline = TRUE))[[1]]
```

+ `comments = TRUE` allows you to use comments and white space to make complex regular expressions more understandable. Spaces are ignored, as is everything after `#`. To match a literal space, you’ll need to escape it: `"\\ "`.

```{r}
phone <- regex("
  \\(?     # optional opening parens
  (\\d{3}) # area code
  [) -]?   # optional closing parens, space, or dash
  (\\d{3}) # another three numbers
  [ -]?    # optional space or dash
  (\\d{3}) # three more numbers
  ", comments = TRUE)

str_match("514-791-8141", phone)
```

+ `dotall = TRUE` allows . to match everything, including `\n`.

There are three other functions you can use instead of `regex()`:

+ `fixed()`: matches exactly the specified sequence of bytes. It ignores all special regular expressions and operates at a very low level. This allows you to avoid complex escaping and can be much faster than regular expressions. The following microbenchmark shows that it’s about 3x faster for a simple example.

```{r}
microbenchmark::microbenchmark(
  
  fixed = str_detect(sentences, fixed("the")),
  
  regex = str_detect(sentences, "the"),
  
  times = 20
)
```

Beware using fixed() with non-English data. It is problematic because there are often multiple ways of representing the same character. For example, there are two ways to define “á”: either as a single character or as an “a” plus an accent:

```{r}
a1 <- "\u00e1"

a2 <- "a\u0301"

c(a1, a2)

a1 == a2
```

They render identically, but because they’re defined differently, `fixed()` doesn’t find a match. Instead, you can use `coll()`, defined next, to respect human character comparison rules:

```{r}
str_detect(a1, fixed(a2))

str_detect(a1, coll(a2))
```

+ `coll()`: compare strings using standard collation rules. This is useful for doing case insensitive matching. Note that `coll()` takes a locale parameter that controls which rules are used for comparing characters. Unfortunately different parts of the world use different rules!

```{r}
# That means you also need to be aware of the difference
# when doing case insensitive matches:

i <- c("I", "İ", "i", "ı")

i


str_subset(i, coll("i", ignore_case = TRUE))

str_subset(i, coll("i", ignore_case = TRUE, locale = "tr"))
```

Both `fixed()` and `regex()` have ignore_case arguments, but they do not allow you to pick the locale: they always use the default locale. You can see what that is with the following code.

```{r}
stringi::stri_locale_info()
```

The downside of `coll()` is speed; because the rules for recognising which characters are the same are complicated, `coll()` is relatively slow compared to `regex()` and `fixed()`.

+ As you saw with `str_split()` you can use `boundary()` to match boundaries. You can also use it with the other functions:

```{r}
x <- "This is a sentence."

str_view_all(x, boundary("word"))

str_extract_all(x, boundary("word"))
```

## Other uses of regular expressions

There are two useful function in base R that also use regular expressions:

+ `apropos()` searches all objects available from the global environment. This is useful if you can’t quite remember the name of the function.

```{r}
apropos("replace")
```

+ `dir()` lists all the files in a directory. The pattern argument takes a regular expression and only returns file names that match the pattern. For example, you can find all the R Markdown files in the current directory with:

```{r}
head(dir(pattern = "\\.Rmd$"))
```

(If you’re more comfortable with “globs” like `*.Rmd`, you can convert them to regular expressions with `glob2rx()`)

## Stringi

stringr is built on top of the *stringi* package.It contains almost every function you might ever need: stringi has 244 functions to stringr’s 49. The packages work very similarly, so you should be able to translate your `stringr` knowledge in a natural way. The main difference is the prefix: str_ vs. stri_.